<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:base="en">
  <title>Reuben Son | Recurse Center</title>
  <subtitle>Weekly writings from my time at Recurse Center</subtitle>
  <link href="https://reubenson.com/feed.xml" rel="self"/>
  <link href="https://reubenson.com/"/>
  <updated>2023-12-04T01:08:10Z</updated>
  <id>https://reubenson.com/</id>
  <author>
    <name>Reuben Son</name>
    <email>reubenson@gmail.com</email>
  </author>
  
  <entry>
    <title>On deploying a neural net to AWS Lambda</title>
    <link href="https://reubenson.com/recurse/week-5/"/>
    <updated>2023-12-04T01:08:10Z</updated>
    <id>https://reubenson.com/recurse/week-5/</id>
    <content type="html">&lt;h2&gt;On deploying a neural net to AWS Lambda&lt;/h2&gt;
&lt;h3&gt;Week 5 at Recurse Center&lt;/h3&gt;
&lt;p&gt;I&#39;m heading into my last week at Recurse, and feeling an excited rush to wrap up the MIDI archive project I began ruminating on the previous week. The shape of it has been slowly coming together, and what remains to be seen is how much I can manage to deploy in the handful of days I have left. At the moment, the project looks something like the following, involving many components beyond just neural net model.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https://mermaid.ink/img/pako:eNplUsFqGzEQ_ZVBJwXiQujNh4LttR1DCgUHmqSbw1ia3RXRStuR1ls35N8r7W5JQ3UaoffezLynV6G8JrEUlfWDapAj3Belg3RW8qgYO-IrWCy-PMnCD8561PD1UBygMpYCVOxbOLhI7CjCilVjznQ18Z8yDdbySHymiYQhUAxwNgh7E5v-9A3rpDKkGkLEaNQimEhQkyNOV--gQact6QlzcxMvs_p6VN_IHUXVwKffpgNf_Tta9NAHSi0hMhpnXA2pOVSewVHPaCGP3Kbt7Sy5yZLbH_cZ_h_mecJsM-ZRbn91nj-yH8eBdrKgzvpLbr_6foQ7bE8aZ8huhDzIAo29wMb6Xg-Yx49s6joZPcEeRthe7icXZu8C_ezJqbSR0xAwWZpaHD9_sKOQdzkg79LTSJoTgYFO2dgZXIzgg1yzHwIxKGvIRVDeOVJzPpnh1UuOK4lNa-SKSZH5m-eJUzuFIc7Ct_J9qcW8VMpuZjOhDu8RTZ8nbTBNMynsU31bOnEtWuIWjU5f8zU_lSI21FIplqnUyC-lKN1bwmEf_fHilFhG7ula9J1OnhUGa8ZWLCu0gd7-ANel7tU?type=png&quot; alt=&quot;drawing&quot; style=&quot;max-width:500px;&quot; /&gt;
&lt;figcaption&gt;Flow diagram for the MIDI Archive&lt;/figcaption&gt;
&lt;!-- source: https://mermaid.live/edit#pako:eNplUsFqGzEQ_ZVBJwXiQujNh4LttR1DCgUHmqSbw1ia3RXRStuR1ls35N8r7W5JQ3UaoffezLynV6G8JrEUlfWDapAj3Belg3RW8qgYO-IrWCy-PMnCD8561PD1UBygMpYCVOxbOLhI7CjCilVjznQ18Z8yDdbySHymiYQhUAxwNgh7E5v-9A3rpDKkGkLEaNQimEhQkyNOV--gQact6QlzcxMvs_p6VN_IHUXVwKffpgNf_Tta9NAHSi0hMhpnXA2pOVSewVHPaCGP3Kbt7Sy5yZLbH_cZ_h_mecJsM-ZRbn91nj-yH8eBdrKgzvpLbr_6foQ7bE8aZ8huhDzIAo29wMb6Xg-Yx49s6joZPcEeRthe7icXZu8C_ezJqbSR0xAwWZpaHD9_sKOQdzkg79LTSJoTgYFO2dgZXIzgg1yzHwIxKGvIRVDeOVJzPpnh1UuOK4lNa-SKSZH5m-eJUzuFIc7Ct_J9qcW8VMpuZjOhDu8RTZ8nbTBNMynsU31bOnEtWuIWjU5f8zU_lSI21FIplqnUyC-lKN1bwmEf_fHilFhG7ula9J1OnhUGa8ZWLCu0gd7-ANel7tU --&gt;
&lt;/figure&gt;
&lt;p&gt;Since the details of this loose architecture diagram are subject to change, I&#39;ll focus on it more in my next post, and instead would like to reflect more on the &lt;code&gt;AWS Lambda&lt;/code&gt; portion of the diagram.&lt;/p&gt;
&lt;p&gt;I&#39;m not yet sure if this project is something I&#39;ll keep working on, or if I&#39;ll let it stay in some form as a proof of concept, but I&#39;d like to deploy in a low-cost and low-maintenance way that would allow me to let it passively exist online with minimal billing and upkeep. While there&#39;s lots of options to deploy ML models to production, I set my sights on Lambda early on because of its usage-based pricing model where I can have the service turned off from most of the day. The model I&#39;ve built so far has pretty limited utility, certainly not sophisticated enough to be useful for generating actual music or aiding the process of composing, so there&#39;s little to warrant it having very much server uptime.&lt;/p&gt;
&lt;p&gt;But this limitation also feels ripe for some creative elaboration, and I&#39;ve been circling around the idea of having the ML model present daily &amp;quot;performances&amp;quot;, in which visitors to the site can hear some music generated by the model. The general inspiration of this comes from &lt;a href=&quot;https://solar.lowtechmagazine.com/&quot;&gt;Low Tech Magazine&lt;/a&gt;, which is hosted on a solar-powered server that sometimes goes down if the weather is cloudy for too long and the battery depletes. Or &lt;a href=&quot;https://radioamnion.net/&quot;&gt;Radio Amnion&lt;/a&gt;, which only broadcasts for a few days around each new moon. There&#39;s something beautiful about these websites that have variable behavior depending on time or atmospheric conditions.&lt;/p&gt;
&lt;p&gt;As for right now, the plan is to have two separate Lambda functions, each of which is only invoked once a day. The first is responsible for serving the machine learning model, and will generate a MIDI sequence that is stored in S3. The second is then responsible for broadcasting that MIDI file over websockets to visitors to the site. Lambdas have a maximum execution time of 15 minutes, which will also limit the duration of the broadcast. An important detail of this, too, is that all visitors to the site will experience the same broadcast at the same time, which to me makes it more of a &amp;quot;performance&amp;quot; than just letting visitors play the MIDI file as they please.&lt;/p&gt;
&lt;p&gt;In terms of implementation, I&#39;ve been struggling to get the model hosted in Lambda, as I hadn&#39;t quite realized how &lt;strong&gt;beefy&lt;/strong&gt; the &lt;code&gt;PyTorch&lt;/code&gt; library is, which I&#39;ve been using to build and train the model, and is far too large for Lambda&#39;s filesize limitations. At first I tried to use an existing tool called &lt;a href=&quot;https://github.com/szymonmaszke/torchlambda&quot;&gt;torchlambda&lt;/a&gt; to minimize and deploy my trained model, but should have taken the fact that it hadn&#39;t been updated in three years as a red flag. In that time, PyTorch has gone through a major version change, and made torchlambda rather unsuitable.&lt;/p&gt;
&lt;p&gt;At the same time, it was interesting to me that torchlambda used something called &lt;a href=&quot;https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html&quot;&gt;torchscript&lt;/a&gt; to compile a model to C++, and vastly minimize the size of source code and dependencies to be deployed to Lambda. But as I was considering going further down this path, &lt;a href=&quot;https://github.com/kenjinp&quot;&gt;Kenny&lt;/a&gt;, a fellow Recurse resident suggested that I look into &lt;a href=&quot;https://onnx.ai/&quot;&gt;https://onnx.ai/&lt;/a&gt;, which aims to bring interoperability to the growing ecosystem of various ML libraries and runtime environments. The Onnx runtime, unlikely PyTorch, is relatively small (~45 MB), and falls within Lambda&#39;s filesize restrictions. After a quick test run, loosely following suggestions &lt;a href=&quot;https://becominghuman.ai/onnx-inference-with-python-in-aws-lambda-f09d08530e87&quot;&gt;here&lt;/a&gt;, I&#39;ve set up a toy model deployed to Lambda using the Onnx runtime packaged into a Lambda layer, and happy to report that it&#39;s functioning as expected!&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Goldberg Variations Variations</title>
    <link href="https://reubenson.com/recurse/week-4/"/>
    <updated>2023-11-26T14:43:26Z</updated>
    <id>https://reubenson.com/recurse/week-4/</id>
    <content type="html">&lt;h2&gt;Goldberg Variations Variations&lt;/h2&gt;
&lt;h3&gt;Week 4 at Recurse Center&lt;/h3&gt;
&lt;p&gt;After seeing my friend Asha Tamirisa give a talk on building a &lt;a href=&quot;https://thekitchen.org/on-view/counter-archiving-the-avant-garde/&quot;&gt;counter-archive of The Kitchen&lt;/a&gt; at &lt;a href=&quot;https://pioneerworks.org/programs/software-for-artists-day-8&quot;&gt;Software for Artists Day&lt;/a&gt; last week, I&#39;ve been thinking more about the overlap between archives and ML training sets, how each deals with concerns of how information perpetuates biases, and produces contestable views of history and reality. Complex socio-economic and political realities are embedded in the objective artifacts that may be included or excluded in both archives and training sets.&lt;/p&gt;
&lt;p&gt;The emergence of certain canonical training sets, like &lt;a href=&quot;https://www.kaggle.com/datasets/wcukierski/enron-email-dataset&quot;&gt;this archive of half a million emails within Enron&lt;/a&gt; obtained by the federal government during its investigation, says something too about how ML is a powerful tool for distilling and operationalizing archives. To turn archives of the near or distant past into substrates that can be mined for the purposes of future prediction or content generation.&lt;/p&gt;
&lt;p&gt;In the information age, big tech often finds a business model in leveraging capital to extract value from assets already in circulation in the wider economy (e.g.ride-sharing or behavioral surplus), and this continues to be the pattern in how today&#39;s LLMs feed on the previously inert archives of the past.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I listened to the music. It was hideous. I have never heard anything like it. It was distorted, diabolical, without sense or meaning, except, perhaps, an alien, disconcerting meaning that should never have been there. I could believe only with the greatest effort that it had once been a Bach Fugue, part of a most orderly and respected work.&lt;/p&gt;
&lt;p&gt;(Excerpt from Philip K. Dick&#39;s &lt;em&gt;The Preserving Machine&lt;/em&gt;, thanks &lt;a href=&quot;https://laurelschwulst.com/&quot;&gt;Laurel&lt;/a&gt;!)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This last week, I&#39;ve been buiding a neural net model trained on MIDI transcriptions of Bach to produce Bach-like music, though not very well at the time of this writing. Around this time last year, I was digging up old MIDI websites from the 1990s, of which I can imagine only a fraction are still online. There are some sizeable training sets available for purposes like this, but I&#39;ve been returning to my old bookmarks instead, and so far have been relying on MIDI transcriptions shared on &lt;a href=&quot;http://www.jsbach.net/&quot;&gt;Dave&#39;s J.S. Bach Page&lt;/a&gt; (first launched in 1996, and last updated in 2010). While revisiting this beautiful website, I came across a figure named John Sankey, known then as the &lt;a href=&quot;https://johnsankey.ca/harpsichord.html&quot;&gt;&lt;em&gt;Harpsichordist to the Internet&lt;/em&gt;&lt;/a&gt;. I was also surprised to see brief mention in his writings on his personal experience in having his &lt;a href=&quot;https://johnsankey.ca/bach.html&quot;&gt;MIDI files stolen and commercialized&lt;/a&gt;, before the longer arc of music piracy during the MP3 age and the rise of Spotify. I&#39;d largely thought of this early period of music file-sharing on the web as a more wholesome era, but it&#39;s helpful to remember that the incentives have been such that much smaller actors than the tech behemoths of today have long taken advantage of opportunities to build products around freely available information on the web.&lt;/p&gt;
&lt;p&gt;With all this in mind, and with my remaining two weeks at Recurse, I&#39;d like to spend a little more time exploring the question of how ML may work towards or alongside archives, rather than ingest them entirely, tracing the faultlines between the archive and the training set.&lt;/p&gt;
&lt;!-- 

been thinking more about how the problematics of archives (tk) bleeds over into the questions of perpetuated biases within training sets for ML systems

- Are ML systems just archives at scale?
- So much effort is leveraged into producing a corpus of training data, but has often been built out of what&#39;s simply available (enron emails?)
- Big tech has always been prone to leveraging capital in order to extract capital from assets already in circulation in the wider economy (the ride-sharing model, the labor behind maintaining Wikipedia)
- A smaller example of the above is found in Sankey, who I discovered while exploring the early music web. How, even then, smaller actors than the tech behemoths today sought out arbitrage opportunities to build products around freely available information
- In the remaining two weeks at Recurse, I&#39;d like to spend a little more time exploring the question of how machine learning may work alongside the project of archive-building, of what divergences may exist between the archive and the training corpus. --&gt;</content>
  </entry>
  
  <entry>
    <title>Alignment Is All You Need</title>
    <link href="https://reubenson.com/recurse/week-3/"/>
    <updated>2023-11-19T15:33:19Z</updated>
    <id>https://reubenson.com/recurse/week-3/</id>
    <content type="html">&lt;h2&gt;Alignment Is All You Need&lt;/h2&gt;
&lt;h3&gt;Week 3 at Recurse Center&lt;/h3&gt;
&lt;p&gt;I&#39;ve just finished my third week at Recurse Center, which means I&#39;m already halfway through my residency here. Although I&#39;m still digesting the material in &lt;a href=&quot;https://karpathy.ai/zero-to-hero.html&quot;&gt;Andrej Karpathy&#39;s Neural Net series&lt;/a&gt;, I&#39;ve finished working through the videos, and in the coming week, I&#39;ll be continuing to implement my own model system to improve my understanding and intuition about these systems.&lt;/p&gt;
&lt;p&gt;The last video in the series is centered around the pivotal &lt;a href=&quot;https://reubenson.com/recurse/week-3/&quot;&gt;Attention is All You Need&lt;/a&gt; paper, which presents the &lt;em&gt;transformer&lt;/em&gt; architecture central to OpenAI&#39;s GPT models. In working through Karpathy&#39;s lecture series, I&#39;m struck by the elegance of neural net architecture, their composition through the repetition of simple elements. And I&#39;m struck too by the degree to which much of the &amp;quot;art&amp;quot; of designing these systems relies on simple arithmetic operations that nudge the state of the system within a regime of being &amp;quot;well-behaved&amp;quot;. Scale is the main thing, which led Rich Sutton to conclude in his &lt;a href=&quot;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&quot;&gt;&lt;em&gt;Bitter Lesson&lt;/em&gt;&lt;/a&gt;: &amp;quot;We have to learn the bitter lesson that building in how we think we think does not work in the long run.&amp;quot;&lt;/p&gt;
&lt;p&gt;Meanwhile ... OpenAI continues to make dramatic headlines, with the sudden firing of Sam Altman. At the time of this writing, conflicts within the board around the speed and safety of the development of their products seem to be at the core of this rift.&lt;/p&gt;
&lt;p&gt;The question of social disalignment around the topic of &lt;em&gt;AI Alignment&lt;/em&gt; within the leadership team at OpenAI is poignant, provocative, and perhaps all too predictable ... disalignment around what it means to build in how we think. Institutions have emergent behaviors and a kind of artificial intelligence too. It seems worth pondering how theories around the problem of alignment in both technologic and social domains emerged at a similar time, as is explored by Orit Halpern in a &lt;a href=&quot;https://www.journals.uchicago.edu/doi/10.1086/717313&quot;&gt;recent paper on the conjoined histories of neural nets and Hayekian neoliberal economics&lt;/a&gt;. Which is to say, &lt;a href=&quot;https://www.reddit.com/r/singularity/comments/17yxl1x/the_head_of_applied_research_at_openai_seems_to/&quot;&gt;e/acc&lt;/a&gt; is nothing new, and alignment has perhaps been out of vogue for nearly a century.&lt;/p&gt;
&lt;p&gt;In my own microcosm of space-time at Recurse, the question of alignment (on a personal scale) feels like a desire for the reassertion of control: in optimizing my time here, having finished projects, the setting and completion of goals. Alignment presumes there&#39;s a reward or loss function at the heart of the model/subject (as is the case for both neural nets and neoliberal economics), but the archetype of the &lt;a href=&quot;https://miguelabreugallery.com/wp-content/uploads/2016/12/GroundingVision_MAG_2017_Sequence_06-1-1024x276.jpg&quot;&gt;meandering line&lt;/a&gt; still feels more appropriate to me. And I wonder, too, about the inverse of Sutton&#39;s &lt;em&gt;Bitter Lesson&lt;/em&gt;, of how the things we build changes how we think, how the logic embedded in formal systems become heuristics for our own sense-making.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Gradually, Then Suddenly</title>
    <link href="https://reubenson.com/recurse/week-2/"/>
    <updated>2023-11-11T18:30:32Z</updated>
    <id>https://reubenson.com/recurse/week-2/</id>
    <content type="html">&lt;h2&gt;Gradually, Then Suddenly&lt;/h2&gt;
&lt;h3&gt;Week 2 at Recurse Center&lt;/h3&gt;
&lt;p&gt;Earlier this week, at an informal dinner centered around the theme of AI Safety, I saw Rob Nail of Singularity University quote &lt;em&gt;&amp;quot;gradually, then suddenly&amp;quot;&lt;/em&gt; (attribution often asigned to Ernest Hemingway, on going bankrupt) in a presentation. It feels equally apt describing the subjective experience of time while at Recurse Center as it does exponential technologies. While I&#39;d been vaguely familiar with AI Safety, this week has gone a long ways towards concretizing my understanding of this emerging field of research and development (thanks in no small part to &lt;a href=&quot;https://github.com/changlinli&quot;&gt;Changlin Li&lt;/a&gt;&#39;s generous efforts to bring me and my cohorts at Recurse up to speed!).&lt;/p&gt;
&lt;p&gt;As of right now, I&#39;ve made it through 4 of the 7 &lt;a href=&quot;https://karpathy.ai/zero-to-hero.html&quot;&gt;videos in Andrej Karpathy&#39;s lecture series on neural nets&lt;/a&gt;, and the first two chapters of the &lt;a href=&quot;https://github.com/fastai/fastbook&quot;&gt;fastbook notebooks&lt;/a&gt;. The majority of my effort is still towards getting up to speed on fundamentals. But that said, it seems worthwhile to think through some of my current questions, assumptions, and intuitions here, if only for my future benefit in tracking how my views shift over time.&lt;/p&gt;
&lt;h3&gt;On AGI&lt;/h3&gt;
&lt;p&gt;AGI (Artificial General Intelligence) seems like a rather squishy term that is dependant on significant, fundamental vagaries: around the nature of our own intelligence, and the question of interpreting/measuring intelligence of an AI system. But it does seem plausible (and probable even) that if we &lt;em&gt;do&lt;/em&gt; build an AGI, we&#39;ll do so before fully understanding how that emergent behavior was achieved. And it will be even longer still, before any meaningful consensus is developed around whether AGI has actually been achieved.&lt;/p&gt;
&lt;p&gt;So given the long arc of developing and recognizing systems that approach AGI, I wonder what it would mean to give space to such systems?&lt;/p&gt;
&lt;!-- In the longer arc of developing systems toward AGI , I wonder what it would mean to give space to such systems --&gt;
&lt;!-- As funding and development of AI outpace AI Safety,  --&gt;
&lt;!-- 
So ... will we reach AGI or what

I have inclinations to debate some of the terminology involved here; ground truth on words that are routinely used to describe current and future technology is fundamentally impossible to pin down. Shortlist of such words: learning, intelligence, artificial, human | machine. And to answer this question is truly beyond me, and I&#39;m happy enough in this case to defer to experts. In some ways, I&#39;m not really interested to address this question at all. But I do wonder what it means to give space to such systems? --&gt;
&lt;p&gt;From what I&#39;ve learned of ML systems thus far, they&#39;re tightly bounded by two constraints: data and computing resources. Model architectures optimize across these two constraints, and the success of current state of the art (LLMs like GPT) relies on transformer-based architecture which rapidly advanced such optimizations. While current transformer-based models may be transient (and there are reasons to hope that they&#39;ll be replaced by architectures that are easier to evaluate according to AI Safety standards), all future architectures will continue to be constrained by data and computing resources on some fundamental level. As these systems scale up in capability, the bottlenecks between subsequent developments will come from doing the most with what data these systems have access to, maximizing the latent knowledge built up from data inflows.&lt;/p&gt;
&lt;!-- As of right now, images and text are the richest sources of data that we have, due to their representational efficiency. --&gt;
&lt;p&gt;Given this, what happens in the limit as we approach AGI? We may currently be in the regime of low-hanging fruit as current state of the art is trained on the internet as its corpus, but richer data-mining would come from greater interaction between models and humans. Heterogeneous systems comprised of humans and AIs interacting would therefore be incentivized from both a training and utility perspective.&lt;/p&gt;
&lt;p&gt;Such heterogeneous systems might perhaps start out being more human-centric. For example, let&#39;s say Apple deploys a new OS that has an AI agent that can automatically answer your emails upon prompting you with a simple question here and there. Much like no one wants an email signature that reads &lt;code&gt;Sent from Reuben&#39;s iPad&lt;/code&gt;, users typically won&#39;t want to send emails that obviously read as being AI-generated. Therefore, in this heterogeneous system, the user will spend time training the AI properly, in order to maintain consistency of tone. Along this path, there will be a tipping point in which it is much easier to give the AI full control over writing one&#39;s emails, than to shut it off and go back to writing your own.&lt;/p&gt;
&lt;p&gt;This in itself doesn&#39;t seem like such a bad thing, but as heterogeneous systems increase in scale, breadth, and interconnectivity, a tendency will exist to make interfaces more and more uniform, to be accessible to both human and AI agents. For example, a new housing development may design an apartment layout that optimizes for human preference and AI inferrability, or a municipalities may decide to revamp its roadways in a way that accomodates driverless cars alongside human drivers.&lt;/p&gt;
&lt;p&gt;The more we increase the surface area of interconnected complex heterogeneous systems (AI augmenting each layer of &lt;a href=&quot;https://thestack.org/&quot;&gt;&lt;em&gt;The Stack&lt;/em&gt; as defined by Benjamin Bratton&lt;/a&gt;), the more difficult it may be to unplug a given set of AI technologies without risking cascading failures across many systems. &lt;a href=&quot;https://ourworldindata.org/ai-timelines&quot;&gt;Many AI researchers seem to be reaching consensus about human-level AI being achieved within 100 years&lt;/a&gt;, but trends towards uniform interfaces will happen long before AGI&#39;s arrival.&lt;/p&gt;
&lt;!-- Such heterogeneous systems might then be characterized in the following ways: --&gt;
&lt;!-- - More uniform interfaces, to be accessible to both humans and AI agents. For example, a new housing development may design an apartment layout that optimizes for human preference and AI inferrability --&gt;
&lt;!-- As a result, I would speculate some of the following to be the case, in the optimization of AGI (along the constraints of compute and data) within the context of increasingly large surface areas of heterogeneous systems inb which humans and actively-training models coexist --&gt;
&lt;!-- - More uniform interfaces (e.g. changing roadway infrastructure to balance the requirements of machine vision and human vision) --&gt;
&lt;!-- - Terminology seems like a fundamentally contentious complex issue when talking about AI. I&#39;m still hesitant to even describe the current technology as AI, as opposed to Machine Learning. At the asymptote of the current development, I&#39;d be more inclined to describe the resulting technology as Machine Intelligence, as opposed to Artificial Intelligence.  --&gt;
&lt;!-- -  --&gt;</content>
  </entry>
  
  <entry>
    <title>Week 1 at Recurse Center (Learning to Paddleboard)</title>
    <link href="https://reubenson.com/recurse/week-1/"/>
    <updated>2023-11-05T17:23:18Z</updated>
    <id>https://reubenson.com/recurse/week-1/</id>
    <content type="html">&lt;h2&gt;Week 1 at Recurse Center (Learning to Paddleboard)&lt;/h2&gt;
&lt;p&gt;Twice this year, I&#39;ve had the good fortune to find myself in spaces filled with people aligned to a common purpose: earlier this year at &lt;a href=&quot;https://www.haystack-mtn.org/&quot;&gt;Haystack Mountain Schoool of Craft&lt;/a&gt;, and now at &lt;a href=&quot;https://www.recurse.com/&quot;&gt;Recurse Center&lt;/a&gt;. These environments foster a regime of expansion and change, and have the power to focus, broaden, and alter one&#39;s sense of purpose. These environments can be quite intense to adjust and recalibrate to, as they involve large changes to the core substrates and infrastructures that compose of one&#39;s daily existence: time, geography, architecture, and community. Much of this is self-evident and not particularly profound to point out, but its lived experience can most immediately be felt in the constellation of affective states that manifest throughout the transition: overhwelm, nervous excitement, disorientation, decision paralysis, fight-or-flight, hyperactivity, dissociation.&lt;/p&gt;
&lt;p&gt;This summer, at Haystack, in addition to learning the &lt;a href=&quot;https://medium.com/@reubenson/foray-into-3d-printing-with-clay-at-haystack-207064511cd&quot;&gt;workflows and processes of ceramic 3D printing&lt;/a&gt;, I went paddleboarding for the very first time. On my initial attempts to stand up and paddle about, I was quickly tossed into the water. The Haystack campus is built on a granite island off the Maine coast, and faces out directly to the ocean. After falling a couple times into the rocking waves, I decided to paddle sitting down instead for a while, but before finally returning to shore, I decided to just stand on the board for a bit, without paddling. I then sat back down again and rowed back to shore. The next day, and each subsequent day on the beach, I found myself immediately able to paddleboard standing up without any further issue. The last time I watched my body in the process of learning was when I began taking ceramics classes in 2019, and it struck me, more or less for the first time, how quickly, and quietly, embodied intelligence is set into motion.&lt;/p&gt;
&lt;p&gt;I think of acclimating to environments like Recurse in a similar way, that the transition still passes through the body, even for something as heady as Recurse&#39;s guiding mission to enable its participants to become radically better programmers over the duration of the residency.&lt;/p&gt;
&lt;div class=&quot;divider-line&quot;&gt;〜〜〜&lt;/div&gt;
&lt;p&gt;So, it&#39;s been a lot of just that, riding the waves through varying affective states, while also slowly refining my sense of purpose here. I&#39;ve been working out a set of priorities and goals, in order to make more tangible that sense of purpose, which I&#39;ll share below. It&#39;s a little sobering that after having just wrapped the first week of my six-week residency here, I&#39;m already nearly a quarter of the way through.&lt;/p&gt;
&lt;p&gt;So far, I&#39;ve committed to going through some amount of &lt;a href=&quot;https://karpathy.ai/zero-to-hero.html&quot;&gt;Andrej Karpathy&#39;s introduction to building neural networks from scratch&lt;/a&gt; and Russell Webb&#39;s &lt;a href=&quot;https://github.com/Russ741/karpathy-nn-z2h&quot;&gt;accompanying worksheets&lt;/a&gt;, though I&#39;m also likely going to switch to or ping-pong between that series and the &lt;a href=&quot;https://github.com/fastai/fastbook&quot;&gt;Fast.ai series&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Guiding principles&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Stay open-ended and cultivate sensitivity, paying attention to what drives my own interests in tech, and see what it is that drives other programmers to similar or divergent interests&lt;/li&gt;
&lt;li&gt;Think of the residency as more of an onboarding, not an end to itself&lt;/li&gt;
&lt;li&gt;Embrace being process-oriented, balanced against being results-driven (but not necessarily working backwards from a predetermined outcome)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Goals&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Learn a new programming language (Python)&lt;/li&gt;
&lt;li&gt;Learn the fundamentals of ML&lt;/li&gt;
&lt;li&gt;Get feedback on previous/existing projects, like &lt;a href=&quot;https://frogchor.us/&quot;&gt;Frog Chorus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Finish and share at least one small project&lt;/li&gt;
&lt;li&gt;Understand current employment landscape / opportunities&lt;/li&gt;
&lt;li&gt;Give focus to both writing code and text (like this entry)&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
</feed>