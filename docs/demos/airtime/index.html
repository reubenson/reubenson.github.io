
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Airtime</title>
    <meta name="description" content="">
    <meta name="keywords" content="reuben son, nyc, software engineer, private chronology, electronic music, ceramics">
    <link rel="stylesheet" href="/styles/main.css">
    <link rel="icon" type="image/png" href="/favicon.png">
    <meta property="og:title" content="Airtime" />
    <meta property="og:description" content="" />
    
    
    
    <meta property="og:image" content="https://reubenson-portfolio.s3.us-east-1.amazonaws.com/assets/portrait_2024.jpg" />
    <meta property="og:type" content="website" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Ibarra+Real+Nova:ital,wght@0,400..700;1,400..700&display=swap" rel="stylesheet">
<style>
  h1, h2, h3, h4, h5, h6 {
    font-family: "Ibarra Real Nova", serif;
    font-weight: 300;
  }
</style>

    <style>
  
  
.broider {
  border-image: url('/public/border-clean.svg') 92 92 repeat;
  border-width: 9px;
  border-style: solid;
}

@media print {
  .broider {
    border: none;
  }
}


</style>

    <script async src="https://www.googletagmanager.com/gtag/js?id=G-90GXJSKXY9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-90GXJSKXY9');
</script>
    
    
    
    
  </head>
  <body class="project ">
    
    <nav class="main-nav">
  <a class="home" href="/">Home</a>
  <a class="about" href="/about">About</a>
  <a class="works" href="/works">Works</a>
  <a class="shop" href="/shop">Shop</a>
  <script>
    const path = window.location.pathname.replace(/\//g, '');
    const navLinks = document.querySelectorAll('nav a');

    if (path === '') {
      navLinks[0].classList.add('active');
    } else {
      navLinks.forEach(link => {
        if (link.href.includes(path)) {
          link.classList.add('active');
        }
      });
    }
  </script>
</nav>

    <div class="top-spacer"></div>
    <div class="content">
      <header>
        <h1>Airtime</h1>
        
      </header>
      
      <div class="project-meta">
        
        
        
        
      </div>
      
      <div class="content-wrapper ">
        <p class="project-grid-item-6">Suddenly, you notice the light; it’s doing something beautiful. You reach for your phone and take a photo. But what if it’s the air itself, and not the light, that has suddenly caught your attention? The AIRTIME mobile app is a way of using your phone as a prompt to be situated within the world through attention to the most diffuse of commons: the air we share.</p>
<figure class="project-grid-item-2">
    <img src="/public/air-phone.jpeg" alt="screenshot of the app" />
    <figcaption>
        This is what your phone looks like while you're using Airtime in <p class="cursive">recording mode</p>
    </figcaption>
</figure>
<p class="project-grid-item-4">In a quiet environment, where little activity is happening around you, open the AIRTIME app. Once you place your phone <strong>screen-down</strong>, the app goes into recording mode: it uses audio from the built-in microphone to generate bespoke “ambient music” (not a direct recording). It then uses <em>musique concrète techniques</em> and generative procedures (e.g. AI diffusion models) to create an interpretation of place: environment distilled into an “aerial snapshot”. Your phone cannot be used for other purposes for the duration of this process, which doesn’t have a predetermined duration and just takes the time you want to give this moment (3-5 minutes might be a good baseline). In this way, the screen serves as a point of departure for how you would like to wield your attention while your phone is “bricked”.</p>
<!-- This is neither meditation nor deep listening, but a moment of reverie and lightness to let your attention drift gently up to the sky.
{.project-grid-item-full} -->
<!-- < insert image or graphics of translation of image and audio into the aerial snapshot > -->
<!-- {.project-grid-item-4} -->
<!-- While sharing some similarities to "ambient music", this sound comes from a specific context and place, . -->
<!-- The smartphone makes certain acts of documentation (i.e. taking a photo) trivially accessible, but our memory and senses drift from the _indexical_. For this project, I found myself going back to Luc Ferrari's _Presque Rien_ and Irv Teibel's _The Psychologically Ultimate Seashore_ as giving poetic license to deviate from faithful representations of objective reality, and to stage the creation of memory as an imaginative and poetic act. -->
<p class="project-grid-item-4">AIRTIME will preserve your <em>aerial snapshots</em>, which are intended to augment your memory of these moments: how the air felt on your skin, in your lungs, and against your ears. In previous projects, I’ve called this a <strong>sound fragrance</strong> because it is an expression of a place and time that reflects the diffuseness of memory. It is a loosely indexical gesture as opposed to a premise of objective representation.
<br>
<br>
A collective archive of <em>aerial snapshots</em> will be preserved within the app and shared with other users. While Spotify and wellness apps can serve personalized - yet contextless - ambient music, AIRTIME addresses the social quality of listening. In sharing traces of our quietest moments with others, it explores a network commons at its most intimate, and ambient. It nurtures the potentiality of daydreaming and <strong>reverie</strong> (see <a href="https://www.beacon.org/The-Poetics-of-Reverie-P16.aspx">Bachelard</a>) in small passing moments in our lives, which can only happen away from the screen.</p>
 <!-- Instead: it uses the phone as a prompt to be situated within the world by listening to the air.  -->
<!-- When you listen back to the snapshot at home, which you can imagine as vapour pouring out of your speakers like a Muji scent diffuser, as if filling your room with other air. -->
<!-- a way of focusing on listening as a way of structuring your perception of reality. and an ambient orientation to community, network commons as an environment which can be de-virtualized into quiet moments in your day.  -->
<!--  -->
<!-- that was hinted at in the late 1960's by compositions like Luc Ferrari's _Presque Rien_ and Irv Teibel's "The Psychologically Ultimate Seashore". -->
<figure
    class="project-grid-item-2"
>
    <!-- <img src="https://f4.bcbits.com/img/a3429394211_16.jpg" alt="screenshot of the app" /> -->
    <!-- <figcaption>
       Album cover for Irv Teibel's <a target="_blank" href="https://en.wikipedia.org/wiki/Environments_(album_series)#:~:text=total%20Environments.-,Environments%201%20(1969),-%5Bedit%5D">Environments</a> (1969), featuring "The Psychologically Ultimate Seashore"
    </figcaption> -->
    <img src="/public/aerial-snapshots-2.jpg" style="border: solid black 1px; margin-top: 0px; padding: 15px" />
    <!-- <img src="https://maison-ona.com/img/works/116_slideshow_1.jpg" alt="screenshot of the app" /> -->
    <figcaption>
       <em>Very</em> loose sketch of UI for an index of aerial snapshots. Music will play when a snapshot is selected. Musical inspiration for AIRTIME comes from the late 1960's, when Luc Ferrari's <a href="https://maison-ona.com/catalog-0059ONA" target="_blank">Presque Rien</a> and Irv Teibel's <a href="https://en.wikipedia.org/wiki/Environments_(album_series)#:~:text=Environments%201%20(1969)" target="_blank">The Psychologically Ultimate Seashore</a> began exploring the fluidity & tension between memory and recording.
    </figcaption>
</figure>
<p class="project-grid-item-4"></p>
<!-- The drift of memory and sensation from the _indexical_ is unavoidable,  -->
<!-- Prior to Brian Eno's coining of the term "ambient music", In the late 1960's Luc Ferari's "Presque Rien" and Irv Teibel's "The Psychologically Ultimate Seashore" arrived at an overlapping set of strategies that dealt with the psychoacoustic aspects of environmental sound. In both cases, site-specific audio recordings were subject to modifications and compositional strategies that deviated from original recordings (and therefore less faithful to the "original") while also composing an experience for the listener that went beyond the merely documentary. While Teibel's piece magnifies a sense of the ocean, Ferrari's "Presque Rien" is a through-composed piece that places naturalistic elements (like cricket sounds) in linear time, which sounds plausible as an unedited recording, but is in fact carefully composed and constructed. -->
<!-- {.project-grid-item-4} -->
<!-- These _aerial snapshots_ are both indexical and -->
<!-- will not accurately represent your experience of that moment, but may help you properly experience it firsthand, and augment your memory of it. Memory and archive working together to create a new experience of the past, a sense of lightness. -->
<!-- <figure
    class="project-grid-item-2"
>
    <img src="https://maison-ona.com/img/works/116_slideshow_1.jpg" alt="screenshot of the app" />
    <figcaption>
        Fragment of Luc Ferrari's score for <a target="_blank" href="https://maison-ona.com/catalog-0059ONA">Presque Rien n°1</a> (1970)
    </figcaption>
</figure> -->
<p class="project-grid-item-full"><em>Keywords: user choreography, attention, protocol art, asmr, sensory ethnography, musique concrète, generative art, archive, memory, calm technology, pneuma, psychoacoustics, deep listening, fluxus</em></p>

      </div>

      
    </div>
    <div class="chop-container">
  <div class="chop-wrapper">
    <div class="chop-border"></div>
    <div class="chop-border inner"></div>
    <svg viewBox="0 0 400 400" width="200" height="200">
    <path id="topPath"
      d="M200,200 m-150,0 a150,150 0 1,1 300,0"
      fill="none"
      transform="rotate(11, 200, 200)"/>
    <path id="bottomPath"
      d="M200,200 m150,0 a150,150 0 1,1 -300,0"
      fill="none"
      transform="rotate(28, 200, 200)"/>
    <text>
      <textPath href="#topPath">
      REUBEN
      </textPath>
    </text>
    <text>
      <textPath href="#bottomPath">
      NOS
      </textPath>
    </text>
    </svg>
    <div class="chop"></div>
  </div>
  <svg style="display: none;">
    <filter id="white-to-transparent">
      <feColorMatrix type="matrix" values="
        1 0 0 0 0
        0 1 0 0 0
        0 0 1 0 0
        -1 -1 -1 1 1
      "/>
    </filter>
  </svg>
</div>

<style>
  .chop-container {
    position: absolute;
    width: 150px;
    height: 150px;
    overflow: hidden;
    opacity: 0.8;
  }

  .chop-wrapper {
    filter: blur(1.1px) contrast(5) url(#white-to-transparent);
    background-color: white;
    height: 100%;
    width: 100%;
  }

  .chop-container svg {
    position: absolute;
    bottom: 0;
    right: 0;
    top: 0;
    left: 0;
    margin: auto;
    overflow: visible;
  }

  .chop {
    width: 30%;
    background-image: url('/public/chop-2.png');
    background-size: contain;
    background-position: center;
    background-repeat: no-repeat;
    transform: scaleX(-1);
    position: absolute;
    bottom: 0;
    right: 0;
    top: 0;
    left: 0;
    margin: auto;
    opacity: 0.9;
  }

  .chop-border {
    border: solid black 2px;
    border-radius: 50%;
    height: 70%;
    width: 70%;
    position: absolute;
    top: 0;
    bottom: 0;
    left: 0;
    right: 0;
    margin: auto;
  }

  .chop-border.inner {
    display: none;
    height: 55%;
    width: 55%;
  }

  .chop-container text {
    font-size: 40px !important;
    letter-spacing: 10px;
    font-weight: bold;
    font-family: Arial, Helvetica, sans-serif;
    opacity: 0.9;
  }

  .homepage .chop-container {
    z-index: 0;
  }

  .project .chop-container,
  .shop-page .chop-container {
    opacity: 0.025;
    z-index: -1;
  }

</style>

<script>
  // randomize position
  const leftRange = [5, 60];
  const topRange = [-5, 15];
  const chopContainer = document.querySelector('.chop-container');
  const randomX = Math.random() * (leftRange[1] - leftRange[0]) + leftRange[0];
  const randomY = Math.random() * (topRange[1] - topRange[0]) + topRange[0];
  chopContainer.style.left = `${randomX}%`;
  chopContainer.style.top = `${randomY}%`;

  // randomize rotation
  const rotationRange = [-50, 100];
  const randomRotation = Math.random() * (rotationRange[1] - rotationRange[0]) + rotationRange[0];
  chopContainer.style.transform = `rotate(${randomRotation}deg)`;
</script>
    <div class="page-border broider"></div>
  </body>
</html>